@inproceedings{hong2025biteeeg,
  title={Bidirectional Time-Frequency Pyramid Network for Enhanced Robust EEG Classification},
  booktitle={2025 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  year={2025},
  organization={IEEE},
  code={https://github.com/cindy-hong/BiteEEG},
  arxiv={2510.10004},
  bibtex_show={true},
  selected={true},
  abbr={BIBM'25},
  additional_info={<br><mark>Oral, AR: 19.6%</mark><br>},  % 使用 HTML 标签增加换行
  preview={bite.png},
  description={<p>Proposed BiTE, an end-to-end EEG classification framework integrating multistream synergy, pyramid attention, and bidirectional adaptive convolutions for robust cross-paradigm BCI tasks. Achieved state-of-the-art performance with both within- and cross-subject generalization. Demonstrated computational efficiency across motor imagery (MI) and steady-state visual evoked potential (SSVEP) paradigms.</p>},  % 确保 description 渲染为段落
}

@inproceedings{yang2026gaussmedact,
  title={Multivariate Gaussian Representation Learning for Medical Action Evaluation},
  booktitle={The 40th Annual AAAI Conference on Artificial Intelligence},
  year={2026},
  selected={true},
  abbr={AAAI'26},
  additional_info={<br><mark>AR: 24.1%</mark><br>},  % 使用 HTML 标签增加换行
  preview={gaussmedact.png},
  description={<p>Developed a novel multivariate Gaussian-based representation learning method for fine-grained temporal and spatial action evaluation, inspired by Gaussian Splatting. Integrated RGB and skeletal joint data modalities for downstream tasks, achieving state-of-the-art performance on benchmarks such as PennAct and CPRCoach.</p>},  % 确保 description 渲染为段落
}

@inproceedings{SAGO_Unlearning,
  title={(Submission) Modeling LLM Unlearning As An Asymmetric Two-task Learning Problem},
  booktitle={The 64th Annual Meeting of the Association for Computational Linguistics},
  year={2026},
  selected={true},
  abbr={ACL'26},
  additional_info={<br><mark>AR: 24.1%</mark><br>},  % 使用 HTML 标签增加换行
  preview={SAGO.png},
  description={<p>Introduced a novel asymmetric two-task learning framework, SAGO, for language model unlearning. The method prioritizes retention while effectively resolving gradient conflicts, improving performance on benchmarks such as WMDP and RWKU, and advancing the Pareto frontier of forgetting and retention.</p>},  % 确保 description 渲染为段落
}

@article{h7virus,
  title={(In Review) Disrupting explicit encoding paradigms: property-interactive transformers decode TCR specificity beyond dataset biases},
  journal={Nature Communications},
  year={2026},
  selected={false},
  preview={h7virus.png},
  description={<p>Utilized Bayesian inference and integrated phylodynamic and phylogeographic analysis to model the global spread and influencing factors of the H7 virus. Contributed to data analysis, modeling, verification, and manuscript preparation.</p>},  % 确保 description 渲染为段落
}
